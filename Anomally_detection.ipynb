{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.layers import BatchNormalization,Conv2D,Conv2DTranspose,LeakyReLU\n",
    "from tensorflow.keras.layers import Activation,Flatten,Dense,Reshape,Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as k\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAutoencoder:\n",
    "    @staticmethod\n",
    "    def build(width,height,depth,filters=(32,64),latentDim = 16):\n",
    "        inputShape = (height,width,depth)\n",
    "        chandim = -1\n",
    "        inputs = Input(shape=inputShape)\n",
    "        x=inputs\n",
    "        for f in filters:\n",
    "            x=Conv2D(f,(3,3),strides=2,padding = \"same\")(x)\n",
    "            x=LeakyReLU(alpha=0.2)(x)\n",
    "            x=BatchNormalization(axis = chandim)(x)\n",
    "        volumeSize = k.int_shape(x)\n",
    "        x=Flatten()(x)\n",
    "        latent = Dense(latentDim)(x)\n",
    "        encoder = Model(inputs,latent,name=\"encoder\")\n",
    "        \n",
    "        latentInputs = Input(shape=(latentDim,))\n",
    "        x = Dense(np.prod(volumeSize[1:]))(latentInputs)\n",
    "        x= Reshape((volumeSize[1],volumeSize[2],volumeSize[3]))(x)\n",
    "        for f in filters[::-1]:\n",
    "            x = Conv2DTranspose(f,(3,3),strides=2,padding=\"same\")(x)\n",
    "            x= LeakyReLU(alpha=0.2)(x)\n",
    "            x=BatchNormalization(axis=chandim)(x)\n",
    "            \n",
    "        x = Conv2DTranspose(depth,(3,3),padding=\"same\")(x)\n",
    "        outputs = Activation(\"sigmoid\")(x)\n",
    "        \n",
    "        decoder = Model(latentInputs,outputs,name=\"decoder\")\n",
    "        \n",
    "        autoencoder = Model(inputs,decoder(encoder(inputs)),name = \"autoencoders\")\n",
    "        \n",
    "        return (encoder,decoder,autoencoder)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import pickle\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unsupervised_dataset(data, labels, validLabel=1,anomalyLabel=3,\n",
    "                               contam=0.01, seed=42):\n",
    "    validIdxs = np.where(labels == validLabel)[0]\n",
    "    anomalyIdxs = np.where(labels == anomalyLabel)[0]\n",
    "    random.shuffle(validIdxs)\n",
    "    random.shuffle(anomalyIdxs)\n",
    "    \n",
    "    i = int(len(validIdxs)*contam)\n",
    "    anomalyIdxs = anomalyIdxs[:1]\n",
    "    \n",
    "    validImages = data[validIdxs]\n",
    "    anomalyImages = data[anomalyIdxs]\n",
    "    \n",
    "    images = np.vstack([validImages,anomalyImages])\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(images)\n",
    "    \n",
    "    return images\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visual_predictions(decoded,gt,samples=10):\n",
    "    outputs = None\n",
    "    for i in range(0,samples):\n",
    "        original = (gt[i] * 255).astype(\"uint8\")\n",
    "        recon = (decoded[i] * 255).astype(\"uint8\")\n",
    "        output = np.hstack([original,recon])\n",
    "        if outputs is None:\n",
    "            outputs = output\n",
    "        else:\n",
    "            outputs = np.vstack([outputs,output])\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sujay J\\Desktop\\PYImage\\my exersize\\Anomally Detection/recon_vis.png\n"
     ]
    }
   ],
   "source": [
    "Vis = os.getcwd()\n",
    "Vis = Vis+\"/recon_vis.png\"\n",
    "print(Vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "INIT_LR = 1e-3\n",
    "BS = 32\n",
    "\n",
    "((trainX,trainY),(testX,testY))= mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = build_unsupervised_dataset(trainX,trainY,validLabel=1,anomalyLabel=3,contam=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.expand_dims(images,axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.astype(\"float32\")/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX,testX) = train_test_split(images,test_size = 0.2,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "(encoder,decoder,autoencoder) = ConvAutoencoder.build(28,28,1)\n",
    "opt = Adam(lr = INIT_LR,decay = INIT_LR/EPOCHS)\n",
    "autoencoder.compile(loss = \"mse\",optimizers = opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5394 samples, validate on 1349 samples\n",
      "Epoch 1/20\n",
      "5394/5394 [==============================] - 27s 5ms/sample - loss: 0.0308 - val_loss: 0.0587\n",
      "Epoch 2/20\n",
      "5394/5394 [==============================] - 21s 4ms/sample - loss: 0.0052 - val_loss: 0.0393\n",
      "Epoch 3/20\n",
      "5394/5394 [==============================] - 21s 4ms/sample - loss: 0.0040 - val_loss: 0.0104\n",
      "Epoch 4/20\n",
      "5394/5394 [==============================] - 20s 4ms/sample - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 5/20\n",
      "5394/5394 [==============================] - 20s 4ms/sample - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 6/20\n",
      "5394/5394 [==============================] - 20s 4ms/sample - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 7/20\n",
      "5394/5394 [==============================] - 21s 4ms/sample - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 8/20\n",
      "5394/5394 [==============================] - 20s 4ms/sample - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 9/20\n",
      "5394/5394 [==============================] - 21s 4ms/sample - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 10/20\n",
      "5394/5394 [==============================] - 21s 4ms/sample - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 11/20\n",
      "5394/5394 [==============================] - 20s 4ms/sample - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 12/20\n",
      "5394/5394 [==============================] - 21s 4ms/sample - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 13/20\n",
      "5394/5394 [==============================] - 21s 4ms/sample - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 14/20\n",
      "5394/5394 [==============================] - 21s 4ms/sample - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 15/20\n",
      "5394/5394 [==============================] - 20s 4ms/sample - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 16/20\n",
      "5394/5394 [==============================] - 21s 4ms/sample - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 17/20\n",
      "5394/5394 [==============================] - 21s 4ms/sample - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 18/20\n",
      "5394/5394 [==============================] - 21s 4ms/sample - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 19/20\n",
      "5394/5394 [==============================] - 21s 4ms/sample - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 20/20\n",
      "5394/5394 [==============================] - 20s 4ms/sample - loss: 0.0017 - val_loss: 0.0023\n"
     ]
    }
   ],
   "source": [
    "h = autoencoder.fit(trainX,trainX,validation_data=(testX,testX),epochs=EPOCHS,batch_size=BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded = autoencoder.predict(testX)\n",
    "vis = visual_predictions(decoded,testX)\n",
    "cv2.imwrite(Vis,vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = np.arange(0,EPOCHS)\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(N,h.history[\"loss\"],label=\"train_loss\")\n",
    "plt.plot(N,h.history[\"val_loss\"],label = \"val_loss\")\n",
    "plt.title(\"training loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"plot.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"dataset\", \"wb\")\n",
    "f.write(pickle.dumps(images))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save(\"model\", save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
